{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "\n",
    "train=pd.read_csv('../datasets/train.csv')\n",
    "test=pd.read_csv('../datasets/test.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_features(train_df):\n",
    "#     train_df['atoms_al']=round(train_df.percent_atom_al*train_df.number_of_total_atoms*2)/2\n",
    "#     train_df['atoms_ga']=round(train_df.percent_atom_ga*train_df.number_of_total_atoms*2)/2\n",
    "#     train_df['atoms_in']=round(train_df.percent_atom_in*train_df.number_of_total_atoms*2)/2\n",
    "\n",
    "#     train_df['al_ga_sum']=train_df['atoms_al']+train_df['atoms_ga']\n",
    "#     train_df['al_in_sum']=train_df['atoms_al']+train_df['atoms_in']\n",
    "#     train_df['ga_in_sum']=train_df['atoms_ga']+train_df['atoms_in']\n",
    "\n",
    "#     train_df['al_minus_ga']=train_df['atoms_al']-train_df['atoms_ga']\n",
    "#     train_df['al_minus_in']=train_df['atoms_al']-train_df['atoms_in']\n",
    "#     train_df['ga_minus_in']=train_df['atoms_ga']-train_df['atoms_in']\n",
    "\n",
    "#     train_df['al_ga_minus_in']=train_df['atoms_al']+train_df['atoms_ga']-train_df['atoms_in']\n",
    "#     train_df['al_in_minus_ga']=train_df['atoms_al']+train_df['atoms_in']-train_df['atoms_ga']\n",
    "#     train_df['ga_in_minus_al']=train_df['atoms_ga']+train_df['atoms_in']-train_df['atoms_al']\n",
    "\n",
    "#     train_df['al_ga_ratio']=train_df['percent_atom_al']/train_df['percent_atom_ga']\n",
    "#     train_df['al_in_ratio']=train_df['percent_atom_al']/train_df['percent_atom_in']\n",
    "#     train_df['ga_in_ratio']=train_df['percent_atom_ga']/train_df['percent_atom_in']\n",
    "\n",
    "#     train_df['al_all_ratio']=train_df['percent_atom_al']/(train_df['percent_atom_ga']+train_df['percent_atom_in'])\n",
    "#     train_df['ga_all_ratio']=train_df['percent_atom_ga']/(train_df['percent_atom_al']+train_df['percent_atom_in'])\n",
    "#     train_df['in_all_ratio']=train_df['percent_atom_in']/(train_df['percent_atom_al']+train_df['percent_atom_ga'])\n",
    "\n",
    "\n",
    "#     train_df['al_ga_sum_ratio']=train_df['al_ga_sum']/train_df['number_of_total_atoms']\n",
    "#     train_df['al_in_sum_ratio']=train_df['al_in_sum']/train_df['number_of_total_atoms']\n",
    "#     train_df['ga_in_sum_ratio']=train_df['ga_in_sum']/train_df['number_of_total_atoms']\n",
    "\n",
    "\n",
    "    train_df['lattice_angle_alpha_degree_minus90']=train_df['lattice_angle_alpha_degree'] - 90.0\n",
    "    train_df['lattice_angle_beta_degree_minus90']=train_df['lattice_angle_beta_degree'] - 90.0\n",
    "    train_df['lattice_angle_gamma_degree_minus90']=train_df['lattice_angle_gamma_degree'] - 90.0\n",
    "    \n",
    "    return(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train=generate_features(train)\n",
    "# test=generate_features(test)\n",
    "\n",
    "bandgap_energy_ev_mean=(np.log(train.groupby('spacegroup')['bandgap_energy_ev'].mean())).to_dict()\n",
    "formation_energy_ev_natom_mean=(np.log(train.groupby('spacegroup')['formation_energy_ev_natom'].mean())).to_dict()\n",
    "\n",
    "train['bandgap_energy_ev_mean']=train['spacegroup'].map(bandgap_energy_ev_mean)\n",
    "train['formation_energy_ev_natom_mean']=train['spacegroup'].map(bandgap_energy_ev_mean)\n",
    "\n",
    "test['bandgap_energy_ev_mean']=test['spacegroup'].map(bandgap_energy_ev_mean)\n",
    "test['formation_energy_ev_natom_mean']=test['spacegroup'].map(bandgap_energy_ev_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ignore_cols=['id','formation_energy_ev_natom','bandgap_energy_ev']\n",
    "\n",
    "predictors=[x for x in train.columns if x not in ignore_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rmsle(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# vector = np.vstack((train[['lattice_vector_1_ang', 'lattice_vector_2_ang','lattice_vector_3_ang']].values,\n",
    "#                     test[['lattice_vector_1_ang', 'lattice_vector_2_ang','lattice_vector_3_ang']].values))\n",
    "\n",
    "# pca = PCA().fit(vector)\n",
    "# train['vector_pca0'] = pca.transform(train[['lattice_vector_1_ang', 'lattice_vector_2_ang','lattice_vector_3_ang']])[:, 0]\n",
    "# test['vector_pca0'] = pca.transform(test[['lattice_vector_1_ang', 'lattice_vector_2_ang','lattice_vector_3_ang']])[:, 0]\n",
    "\n",
    "# predictors.append('vector_pca0')\n",
    "\n",
    "\n",
    "\n",
    "Y_feen = np.log(train['formation_energy_ev_natom']+1)\n",
    "Y_bee = np.log(train['bandgap_energy_ev']+1)\n",
    "\n",
    "\n",
    "X=train[predictors].as_matrix()\n",
    "test_mat=test[predictors].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_models(X,Y,test,k_folds):\n",
    "\n",
    "    oof = np.empty(len(X))\n",
    "    sub_preds = np.zeros(len(test))\n",
    "\n",
    "    kf = KFold(n_splits=k_folds)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        estimator = XGBRegressor( learning_rate=0.05, n_estimators=1000, max_depth=3,\\\n",
    "                                  min_child_weight=5, gamma=0, subsample=0.85, colsample_bytree=0.85,\\\n",
    "                                  objective= 'reg:linear', seed=30,)\n",
    "        estimator.fit(X_train,y_train,eval_set=[(X_train, y_train), (X_test, y_test)],\\\n",
    "                      eval_metric='rmse', verbose=False,early_stopping_rounds=20) \n",
    "\n",
    "        oof[test_index] = estimator.predict(X_test)\n",
    "\n",
    "\n",
    "        # Update submission\n",
    "        sub_preds += estimator.predict(test_mat) / k_folds\n",
    "    return oof, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026458712632948578"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_feen, sub_preds_feen = train_models(X,Y_feen,test_mat,k_folds=10)\n",
    "rmsle(oof_feen,Y_feen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04998604012842432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_bee, sub_preds_bee = train_models(X,Y_bee,test_mat,k_folds=10)\n",
    "rmsle(Y_bee,oof_bee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "estimator = XGBRegressor( learning_rate=0.05, n_estimators=1000, max_depth=3,\\\n",
    "                          min_child_weight=5, gamma=0, subsample=0.85, colsample_bytree=0.85,\\\n",
    "                          objective= 'reg:linear', seed=30,)\n",
    "estimator.fit(X,Y_feen) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dsx_ml.ml import save\n",
    "saved_model_output = save(name='NomadXgboost', model=model, test_data=test_data,algorithm_type='Regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5 with DSX Spark 2.2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
